{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<shelve.DbfilenameShelf object at 0x7f750c24b160>\n",
      "['Agent', 'AgentClass', 'CommunicationP3DX', 'Empty', 'Memory', 'QNetwork', 'QNetworkCNN', 'Q_1', 'StepLR', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '__warningregistry__', 'actions_angular', 'actions_linear', 'datetime', 'device', 'evaluate', 'filename', 'goal_zones_x', 'goal_zones_y', 'hist_dict', 'key', 'laser_scan_state_type_atual', 'main', 'my_shelf', 'n_sectors', 'path', 'pause_physics_client', 'performance', 'reset_simulation', 'select_action', 'str_hora_agr', 'str_hora_inicio_treino', 'theta_atual', 'train', 'unpause_physics_client', 'update_parameters']\n"
     ]
    }
   ],
   "source": [
    "# ddqn = DDQN(latent_dim, action_dim).to(device)\n",
    "# optimizer = torch.optim.Adam(ddqn.parameters(), lr=learning_rate)\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for (state, action, reward, next_state, done) in replay_buffer:\n",
    "#         state = vae.encoder(state).detach()\n",
    "#         next_state = vae.encoder(next_state).detach()\n",
    "#         q_values = ddqn(state)\n",
    "#         next_q_values = ddqn(next_state)\n",
    "#         target = reward + gamma * torch.max(next_q_values, dim=1)[0] * (1 - done)\n",
    "#         loss = F.mse_loss(q_values.gather(1, action.unsqueeze(1)), target.unsqueeze(1))\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from CommunicationP3DX import CommunicationP3DX\n",
    "from Agent import AgentClass\n",
    "from std_srvs.srv import Empty\n",
    "import rospy\n",
    "import time\n",
    "import shelve\n",
    "import os\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "workspace_folder_path ='/media/xnd/7A309A87309A49D1/sia_23/25k/'\n",
    "\n",
    "agg_method = 'mean'\n",
    "n_sectors = 6\n",
    "\n",
    "workspace = shelve.open(workspace_folder_path+'/wsh_{metodo}{n_setores}completo.out'.format(\n",
    "        metodo = agg_method,n_setores = n_sectors))\n",
    "# true if the key exists\n",
    "vars = list(workspace.keys())\n",
    "print(workspace)\n",
    "print(vars)\n",
    "hist_dict = workspace['hist_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, input_dim, latent_dim):\n",
    "#         super(VAE, self).__init__()\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Linear(input_dim, 500),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(500, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, latent_dim)\n",
    "#         )\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(latent_dim, 500),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(500, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, input_dim),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         z = self.encoder(x)\n",
    "#         return self.decoder(z), z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_ep_idx = 0\n",
      "random_ep_idx = 100\n",
      "random_ep_idx = 200\n",
      "random_ep_idx = 300\n",
      "random_ep_idx = 400\n",
      "random_ep_idx = 500\n",
      "random_ep_idx = 600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mfor\u001b[39;00m scan_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m727\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             new_episode_positions[\u001b[39m'\u001b[39m\u001b[39mscan_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(scan_idx)] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric([\u001b[39mfloat\u001b[39m(scan_i)  \u001b[39mfor\u001b[39;00m scan_i \u001b[39min\u001b[39;00m trasnposed_scans[scan_idx]])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         df_episode_positions \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([df_episode_positions,new_episode_positions])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     df_episode_positions \u001b[39m=\u001b[39m df_episode_positions\u001b[39m.\u001b[39mreplace(np\u001b[39m.\u001b[39mInf, np\u001b[39m.\u001b[39mNaN)\u001b[39m.\u001b[39mfillna(\u001b[39m5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m df_episode_positions\u001b[39m.\u001b[39mto_pickle(\u001b[39m'\u001b[39m\u001b[39mdataset_large_2_vae.pickle\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39m1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m     objs,\n\u001b[1;32m    370\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    379\u001b[0m )\n\u001b[0;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/pandas/core/reshape/concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    618\u001b[0m )\n\u001b[1;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[1;32m    620\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/pandas/core/internals/concat.py:199\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m _concatenate_array_managers(mgrs_indexers, axes, concat_axis, copy)\n\u001b[1;32m    197\u001b[0m mgrs_indexers \u001b[39m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers)\n\u001b[0;32m--> 199\u001b[0m concat_plans \u001b[39m=\u001b[39m [\n\u001b[1;32m    200\u001b[0m     _get_mgr_concatenation_plan(mgr, indexers) \u001b[39mfor\u001b[39;00m mgr, indexers \u001b[39min\u001b[39;00m mgrs_indexers\n\u001b[1;32m    201\u001b[0m ]\n\u001b[1;32m    202\u001b[0m concat_plan \u001b[39m=\u001b[39m _combine_concat_plans(concat_plans, concat_axis)\n\u001b[1;32m    203\u001b[0m blocks \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/pandas/core/internals/concat.py:200\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[39mreturn\u001b[39;00m _concatenate_array_managers(mgrs_indexers, axes, concat_axis, copy)\n\u001b[1;32m    197\u001b[0m mgrs_indexers \u001b[39m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers)\n\u001b[1;32m    199\u001b[0m concat_plans \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 200\u001b[0m     _get_mgr_concatenation_plan(mgr, indexers) \u001b[39mfor\u001b[39;00m mgr, indexers \u001b[39min\u001b[39;00m mgrs_indexers\n\u001b[1;32m    201\u001b[0m ]\n\u001b[1;32m    202\u001b[0m concat_plan \u001b[39m=\u001b[39m _combine_concat_plans(concat_plans, concat_axis)\n\u001b[1;32m    203\u001b[0m blocks \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/pandas/core/internals/concat.py:309\u001b[0m, in \u001b[0;36m_get_mgr_concatenation_plan\u001b[0;34m(mgr, indexers)\u001b[0m\n\u001b[1;32m    306\u001b[0m blklocs \u001b[39m=\u001b[39m mgr\u001b[39m.\u001b[39mblklocs\n\u001b[1;32m    308\u001b[0m plan \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 309\u001b[0m \u001b[39mfor\u001b[39;00m blkno, placements \u001b[39min\u001b[39;00m libinternals\u001b[39m.\u001b[39mget_blkno_placements(blknos, group\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    311\u001b[0m     \u001b[39massert\u001b[39;00m placements\u001b[39m.\u001b[39mis_slice_like\n\u001b[1;32m    312\u001b[0m     \u001b[39massert\u001b[39;00m blkno \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# creating dummy targets (float values)\n",
    "# episode = 9900\n",
    "\n",
    "random_episodes =np.random.randint(2000,20000,15000)\n",
    "for random_ep_idx, episode in enumerate(random_episodes):\n",
    "    if random_ep_idx%100==0: print('random_ep_idx = {ep_id}'.format(ep_id =random_ep_idx))\n",
    "    # shape = (727, 16)\n",
    "    trasnposed_scans = np.asarray([np.asarray(scan_i) for scan_i in hist_dict['scan'][episode]]).transpose()    \n",
    "\n",
    "    if random_ep_idx==0:\n",
    "        df_episode_positions = pd.DataFrame({#'i':range(len(hist_dict['pos'][episode])),\n",
    "                                            'x':[pos[0] for pos in hist_dict['pos'][episode]], \n",
    "                                            'y':[pos[1] for pos in hist_dict['pos'][episode]]})\n",
    "\n",
    "        for scan_idx in range(0,727):\n",
    "            df_episode_positions['scan_'+str(scan_idx)] = pd.to_numeric([float(scan_i)  for scan_i in trasnposed_scans[scan_idx]])\n",
    "\n",
    "    else:\n",
    "        new_episode_positions = pd.DataFrame({'x':[pos[0] for pos in hist_dict['pos'][episode]], \n",
    "                                            'y':[pos[1] for pos in hist_dict['pos'][episode]]})\n",
    "        \n",
    "        for scan_idx in range(0,727):\n",
    "            new_episode_positions['scan_'+str(scan_idx)] = pd.to_numeric([float(scan_i)  for scan_i in trasnposed_scans[scan_idx]])\n",
    "\n",
    "        df_episode_positions = pd.concat([df_episode_positions,new_episode_positions])\n",
    "        \n",
    "\n",
    "    df_episode_positions = df_episode_positions.replace(np.Inf, np.NaN).fillna(5)\n",
    "\n",
    "df_episode_positions.to_pickle('dataset_large_2_vae.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_episode_positions = pd.read_pickle('dataset_large_vae.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.5975,  1.8683,  5.0000,  ...,  2.1260,  2.2045,  2.2320],\n",
      "        [-3.0583,  1.6770,  1.5989,  ...,  5.0000,  5.0000,  5.0000],\n",
      "        [-2.6804,  2.1618,  3.0064,  ...,  5.0000,  5.0000,  5.0000],\n",
      "        ...,\n",
      "        [-8.4203,  1.2900,  5.0000,  ...,  1.1412,  1.1663,  1.1652],\n",
      "        [-9.0506,  1.2788,  5.0000,  ...,  2.4888,  2.5070,  2.5613],\n",
      "        [-9.7174,  0.5533,  5.0000,  ...,  0.4275,  0.4347,  0.4563]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# creating tensor from targets_df \n",
    "data = df_episode_positions.values # .to_numpy()\n",
    "torch_tensor = torch.tensor(data)\n",
    "\n",
    "# printing out result\n",
    "print(torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(729, 400)\n",
    "        self.fc21 = nn.Linear(400, 5)  # mu layer\n",
    "        self.fc22 = nn.Linear(400, 5)  # logvariance layer\n",
    "        self.fc3 = nn.Linear(5, 400)\n",
    "        self.fc4 = nn.Linear(400, 729)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = torch.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = torch.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 729))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "# z = self.encoder(x)\n",
    "#         return self.decoder(z), z\n",
    "\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3371242401.921875\n",
      "-7287151369.921875\n",
      "-11243574601.921875\n",
      "-15207751169.921875\n",
      "-19191050305.921875\n",
      "-23198194297.921875\n",
      "-4045917688.0\n",
      "-8078692008.0\n",
      "-12123004416.0\n",
      "-16175966008.0\n",
      "-20239872128.0\n",
      "-24304238152.0\n",
      "-4059578856.0\n",
      "-8136874952.0\n",
      "-12207082608.0\n",
      "-16283093816.0\n",
      "-20352916176.0\n",
      "-24423438120.0\n",
      "-4073549960.0\n",
      "-8154821512.0\n",
      "-12240129296.0\n",
      "-16313426248.0\n",
      "-20393533080.0\n",
      "-24467595120.0\n",
      "-4069311392.0\n",
      "-8158788072.0\n",
      "-12236709432.0\n",
      "-16316644624.0\n",
      "-20395565816.0\n",
      "-24484623256.0\n",
      "-4091926768.0\n",
      "-8174516640.0\n",
      "-12269229080.0\n",
      "-16346465152.0\n",
      "-20429471208.0\n",
      "-24506536768.0\n",
      "-4079634224.0\n",
      "-8170534896.0\n",
      "-12263820240.0\n",
      "-16353351832.0\n",
      "-20434109304.0\n",
      "-24526055200.0\n",
      "-4087842112.0\n",
      "-8174003048.0\n",
      "-12259017088.0\n",
      "-16351266352.0\n",
      "-20439743936.0\n",
      "-24530808656.0\n",
      "-4087944224.0\n",
      "-8178897880.0\n",
      "-12258142368.0\n",
      "-16344911888.0\n",
      "-20432952216.0\n",
      "-24524340200.0\n",
      "-4097703328.0\n",
      "-8186538080.0\n",
      "-12281203672.0\n",
      "-16377205984.0\n",
      "-20452947560.0\n",
      "-24544915808.0\n",
      "-4087309448.0\n",
      "-8179724176.0\n",
      "-12276719024.0\n",
      "-16364069400.0\n",
      "-20443349176.0\n",
      "-24550593968.0\n",
      "-4084121480.0\n",
      "-8185949040.0\n",
      "-12285298512.0\n",
      "-16375635120.0\n",
      "-20479305808.0\n",
      "-24554319128.0\n",
      "-4093657184.0\n",
      "-8167901592.0\n",
      "-12268078296.0\n",
      "-16376422592.0\n",
      "-20468706720.0\n",
      "-24554129864.0\n",
      "-4079857504.0\n",
      "-8168223552.0\n",
      "-12268758752.0\n",
      "-16363761912.0\n",
      "-20468353664.0\n",
      "-24558213000.0\n",
      "-4093067432.0\n",
      "-8191869184.0\n",
      "-12285816880.0\n",
      "-16376255760.0\n",
      "-20473235408.0\n",
      "-24563086368.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m batch_idx\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb#W4sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m (inputs, ) \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/xnd/Desktop/sia_DRL_2023/vae_training.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     batch_idx\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[1;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/miniconda3/envs/DRL/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_dim = 727+2 # 727 laser readings + 2 pos readings\n",
    "latent_dim = 5\n",
    "num_epochs = 100\n",
    "batch_size = 500\n",
    "\n",
    "# Convert numpy array to PyTorch tensor\n",
    "data_tensor = torch.from_numpy(data)\n",
    "\n",
    "# Create a TensorDataset from the tensor\n",
    "dataset = TensorDataset(data_tensor)\n",
    "\n",
    "# Create a DataLoader from the TensorDataset\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr=1e-12\n",
    "num_episodes = num_epochs\n",
    "initial_lr = lr\n",
    "final_lr = lr*1e-2\n",
    "n_updates = num_episodes*0.7\n",
    "lr_gamma =  (final_lr / initial_lr)**(1 / n_updates) # gamma\n",
    "\n",
    "# vae = VAE2(input_dim, latent_dim).to(device)\n",
    "\n",
    "# Example of how to use this loss function:\n",
    "vae = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 729), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "    \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    batch_idx=0\n",
    "    for (inputs, ) in dataloader:\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        batch_idx+=1\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = vae(inputs)\n",
    "        loss = loss_function(recon_batch, inputs, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx%50==0:print(train_loss)\n",
    "\n",
    "    # for (inputs,) in dataloader:\n",
    "    #     inputs = inputs.to(torch.float32).to(device)\n",
    "    #     outputs, _ = vae(inputs)\n",
    "    #     printloss =  F.mse_loss(outputs, inputs, reduction='sum') # \n",
    "    #     loss = F.binary_cross_entropy(outputs, inputs, reduction='sum')\n",
    "    #     optimizer.zero_grad()\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
